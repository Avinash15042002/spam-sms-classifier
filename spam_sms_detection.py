# -*- coding: utf-8 -*-
"""SPAM SMS DETECTION.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14pqeurXLv7y8485nRTR78dOsL3PYmE5d
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('spam.csv')

df.isnull().sum()

df.rename(columns={'Category':'target','Message':'text'},inplace = True)

from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()
df['target']= encoder.fit_transform(df['target'])

df.drop_duplicates(keep='first',inplace=True)

df['target'].value_counts()

plt.pie(df['target'].value_counts(),labels=['ham','spam'],autopct='%0.2f',explode=(0.01,0.03))
plt.show()

import nltk
nltk.download('punkt')

df['num_characters']=df['text'].apply(len)

df

df['num_words']=df['text'].apply(lambda x : len(nltk.word_tokenize(x)))

df

df['num_sentence']=df['text'].apply(lambda x : len(nltk.sent_tokenize(x)))

df

df[['num_characters','num_words','num_sentence']].describe()

df[df['target']==0][['num_characters','num_words','num_sentence']].describe()

df[df['target']==1][['num_characters','num_words','num_sentence']].describe()

plt.figure(figsize=(12,8))
sns.histplot(df[df['target'] == 0]['num_characters'])
sns.histplot(df[df['target'] == 1]['num_characters'],color='red')

sns.pairplot(df,hue='target')

numerical_df = df.select_dtypes(include=['number'])
sns.heatmap(numerical_df.corr(), annot=True)

from nltk.corpus import stopwords
nltk.download('stopwords')
from nltk.stem.porter import PorterStemmer
ps = PorterStemmer()
import string
def transform_text(text):
  text = text.lower()
  text = nltk.word_tokenize(text)
  y = []
  for i in text:
    if i.isalnum():
      y.append(i)


  text = y[:]
  y.clear()

  for i in text:
    if i not in stopwords.words('english') and i not in string.punctuation:
      y.append(i)

  text = y[:]
  y.clear()

  for i in text:
    y.append(ps.stem(i))

  return " ".join(y)

transform_text('Hello, && 23 ^^ ,,, loving having dancing how are you?')

df['transformed_text'] = df['text'].apply(transform_text)

df

from wordcloud import WordCloud
wc = WordCloud(width=500,height=500,min_font_size=10,background_color='white')

spam_wc = wc.generate(df[df['target'] == 1]['transformed_text'].str.cat(sep=" "))

plt.imshow(spam_wc)

ham_wc = wc.generate(df[df['target'] == 0]['transformed_text'].str.cat(sep=" "))

plt.imshow(ham_wc)

spam_corpus = []
for msg in (df[df['target']==1]['transformed_text']).tolist():
  for word in msg.split():
    spam_corpus.append(word)

from collections import Counter
spam_corpus_df = pd.DataFrame(Counter(spam_corpus).most_common(30), columns=['Word', 'Frequency'])

# Use the DataFrame directly in the barplot function
sns.barplot(x='Word', y='Frequency', data=spam_corpus_df)
plt.xticks(rotation = 'vertical')
plt.show()

ham_corpus = []
for msg in (df[df['target']==0]['transformed_text']).tolist():
  for word in msg.split():
    ham_corpus.append(word)

Counter(ham_corpus).most_common(30)

ham_corpus_df = pd.DataFrame(Counter(ham_corpus).most_common(30), columns=['Word', 'Frequency'])

# Use the DataFrame directly in the barplot function
sns.barplot(x='Word', y='Frequency', data=ham_corpus_df)
plt.xticks(rotation = 'vertical')
plt.show()

from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer
cv = CountVectorizer()
tfidf = TfidfVectorizer(max_features = 3000)

X = tfidf.fit_transform(df['transformed_text']).toarray()

X

y = df['target'].values

y

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state=2)

X_test.shape

y_test.shape

from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB
from sklearn.metrics import accuracy_score,confusion_matrix,precision_score

gnb = GaussianNB()
mnb = MultinomialNB()
bnb = BernoulliNB()

gnb.fit(X_train,y_train)
y_pred1 = gnb.predict(X_test)
print(accuracy_score(y_test,y_pred1))
print(confusion_matrix(y_test,y_pred1))
print(precision_score(y_test,y_pred1))

mnb.fit(X_train,y_train)
y_pred2 = mnb.predict(X_test)
print(accuracy_score(y_test,y_pred2))
print(confusion_matrix(y_test,y_pred2))
print(precision_score(y_test,y_pred2))

bnb.fit(X_train,y_train)
y_pred3 = bnb.predict(X_test)
print(accuracy_score(y_test,y_pred3))
print(confusion_matrix(y_test,y_pred3))
print(precision_score(y_test,y_pred3))

import pickle
pickle.dump(tfidf,open('vectorizer.pkl','wb'))
pickle.dump(mnb,open('model.pkl','wb'))